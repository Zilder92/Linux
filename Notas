################################Servicio apache #############################
 
#Agendamiento reiniciar apache
 
 
/etc/init.d/Servidor_Apache.sh status
 
/etc/init.d/Servidor_Apache.sh stop
 
/etc/init.d/Servidor_Apache.sh start
 
/etc/init.d/Servidor_Apache.sh status
 
 
validar procesos con =
 
ps -fea |grep httpd
 
si se evidencian procesos pegados darles kill -9 y el codigo

############AIX DATAPROCESOR ###########################
lssrc -s inetd ----------> estatus der servicio de inetd
stopsrc -s inetd ---------> para estopiar el servicio
startsrc -s inetd --------> para inicializarlo
############AIX DATAPROCESOR ###########################
########################### HP-UX ###########################

dataprotector

ps -fea| grep /bsm ---> para ver los procesos de dataprotector
swlist -l product ---> para ver los servicios

/sbin/init.d/inetd stop
/sbin/init.d/inetd start
########################### HP-UX ###########################

1- lsblk e identificar el disco (ultimo)
con el comando ls -ltr /dev/sdm se puede ver de cuanto presentaron el disco
2- fdisk /dev/sdj (validamos si el disco tiene particiones lo cual no deberia ser asi)
3- vgs validamos los volume groups
4- pvcreate /dev/sdj (Es el comando que inicializa un disco o una partición para ser utilizado como un volumen físico en LVM.)
5- vgcreate vgaud /dev/sdj (vgaud es el volume group y el sdj es el disco, aca es donde se asigna)
sudo vgdisplay -v vgdata se puede ver si esta creado el vgdata o el vg a crear
6- lvcreate -L+199.9G -n lv_auditlog /dev/mapper/vgaud (se le asigna los 200GB al) o tambien con sudo lvcreate -l 100%FREE -n lvbackup vgbackup
lvcreate: Es el comando utilizado para crear un volumen lógico (LV) dentro de un grupo de volúmenes (VG) en el contexto de la gestión de volúmenes lógicos (LVM).
-L +199.9G: Especifica el tamaño del volumen lógico que deseas crear. La opción +199.9G indica que se agregará 199.9 GB de espacio al volumen lógico en lugar de asignar exactamente 199.9 GB. Esto es útil si estás extendiendo un volumen lógico ya existente.
-n lv_auditlog: Esta opción asigna un nombre al volumen lógico que estás creando. En este caso, el nombre será lv_auditlog.
/dev/mapper/vgaud: Especifica el grupo de volúmenes (vgaud) donde se creará o extenderá el volumen lógico. El camino /dev/mapper/vgaud es la forma común de referirse a un grupo de volúmenes en LVM.
Este comando crea un nuevo volumen lógico llamado lv_auditlog dentro del grupo de volúmenes vgaud, añadiendo 199.9 GB al tamaño del volumen lógico. Si el volumen lógico lv_auditlog ya existía, este comando aumentaría su tamaño en 199.9 GB.
7- df -hT (se valida que tipo fs es en este caso es xfs)
8- mkfs.xfs /dev/mapper/vgaud/lv_auditlog (convierte el fs a xfs)
9- mkdir -p /usr/sap/Au
ditLog (crea la ruta)
10- backup: mkdir /opt/.backup
cp -p /etc/fstab /opt/.backup/fstab_30-08-2024_ec5149n
11- editar el archivo fstab
vim /etc/fstab
/dev/mapper/vgaud-lv_auditlog /usr/sap/AuditLog xfs     defaults        1 2 (el 1 2 son para file system que no sean del s.o y 0.0 deben ponerse)
12- mount -a



------------------------------------------------------------------------------------------------------------------------------------------------------------------------
con sudo ldm list
NAME             STATE      FLAGS   CONS    VCPU  MEMORY   UTIL  NORM  UPTIME
primary          active     -n-cv-  UART    8     16G      8.0%  7.9%  1517d 6h (siempre es la maquina fisica primero el resto son ldom)
EYQ0016          active     -n----  5009    32    48G       17%   17%  358d 19h
FDB0117          active     -n----  5004    16    64G       10%   10%  12d 8h 6m
FDB0396          active     -n----  5002    32    34048M   0.9%  0.9%  2d 1h 13m
FDB0462          active     -n----  5000    16    70G      5.7%  5.6%  185d 22h
FDB0466          active     -n----  5003    8     16G      1.5%  1.4%  320d 11h
RKFL000473       active     -n----  5001    4     32G      0.5%  0.5%  6d 22h 7m


para saber que maquina fisica almacena la virtual es con virtinfo -a 
para ver las hba wwn en solaris es con (esto se hace en los ldom o maquinas fisicas que almacenan las virtuales) : sudo fcinfo hba-port
------------------------------------------------------------------------------------------------------------------------------------------------------------------------

strace df -h ( le hacemos seguimiento al punto de montaje que queda pegado)
luego le damos umount -l



cat /etc/exports
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
rpcbind.service abre un puerto creo que es el 1111 y permite montar los servicios de nfs-client.target
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Para reiniciar los servicios apache de las maquinas AGENDAMIENTOS se hace lo siguiente
primero se valida con ps -fea | httpd 
ANTES DE MATAR PROCESO SE DEBE PREGUNTAR SI EL SERVICIO ESTA ARRIBA 
si hay proceso matarlo con kill -9
luego ejecutar sh /etc/init.d/Servidor_Apache.sh start
luego para ver el estado
sh /etc/init.d/Servidor_Apache.sh status
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
cuando no aparezca fs

se valida el fstab a ver si hay nfs
se procede a dar sudo mount para montarlo

se hace prueba

luego sudo umount/mnt

si aparece:


umount.nfs: /mnt: device is busy
umount.nfs: /mnt: device is busy

ejecutar sudo umount -l /mnt
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Linea creacion HPUX
sudo useradd -g admserve -d /export/home/ec5149n -m -c "AlgarTech SA - Administrador N1 Unix Silder Mauricio Quinones Sanchez - WO0000002726419 - Administrador Unix N1 - CC 1096215149" -s /usr/bin/ksh ec5149n

sudo useradd -g admtmx -d /home/ec5149n -m -c "AlgarTech SA - Administrador N1 Unix Silder Mauricio Quinones Sanchez - WO0000002726419 - Administrador Unix N1 - CC 1096215149" -s /usr/bin/ksh ec5149n




Linea de creación
Maquinas DC
useradd -d /home/ec5149n -g admtmx -G admtmx -s /bin/bash -c "AlgarTech SA -Administrador N1 Unix Silder Mauricio Quinones Sanchez - C.C 1096215149 - RF1574463" ec5149n

Linea solaris

useradd -c /home/ec5149n -g admtmx -G admtmx -s /bin/bash -c "AlgarTech SA - Datacenter unix N1 Silder Mauricio Quinones Sanchez - C.C 1096215149 - RF1574463" ec5149n

Maquinas IT
useradd -d /home/ec5149n -g admtmx  -G admtmx  -s /bin/bash -c "AlgarTech SA - Administrador N1 Unix - Silder Mauricio Quinones Sanchez - C.C 1096215149 - WO0000002726419" ec5149n
------------------------------------------------------------------------------------
find audit.log* |grep -v gz (el -v gz es para omitir los comprimidos)
find audit.log.* -type f |grep -v gz > comprimir.txt
xargs gzip -9f < comprimir.txt ----> xargs es como hacerle un cat al archivo txt
------------------------------------------------------------------------------------
Se valida la lun que se presenteto desde almacenamiento ---> multipath -ll | grep 6000d31001568e00000000000000028b
Si no se ve la lun, ejecutar script sh /usr/bin/tools/scanhba
Sacar copia al multpath para asignar alias al disco, segun el consecutivo --> cp -r /etc/multipath.conf /opt/.backup/multipath.conf-15092023
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------- Validar acceso por ssh ---------------------------------------------
1. id usuario
2. cat /etc/ssh/sshd_config (se mira si esta el grupo del usuario en la sesion de AllowGroups root monitoring )
3. se valida si esta la ruta ls /opt/.backup si no crear con mkdir /opt/.backup
4. se copia con cp -p /etc/ssh/sshd_config /opt/.backup
5. se ingresa con vim luego tecla i para insert, se coloca el grupo en la seccion de AllowGroups luego se da escape y se da :wq! para salir y guardar.
6. se debe reiniciar el servicio systemctl restart sshd una vez reiniciado ya permite.
--------------------------------------------- Validar acceso por ssh ---------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
autounix@172.22.16.179:/transfer
cd usr/bin/tools 
ls
sh infroprepos.sh
validar en 
/tmp/HP 
o
/var/tmp/infoprepos
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Valida dpool

Primero 
zpool list

NAME    SIZE  ALLOC   FREE  CAP  DEDUP    HEALTH  ALTROOT
dpool  99.5G  90.2G  9.31G  90%  1.00x    ONLINE  -
epool  49.8G  30.8G  18.9G  61%  1.00x  DEGRADED  -
rpool  99.5G  60.7G  38.8G  61%  2.12x    ONLINE  -

se visualiza el que este degraded es una falla física o desconexiones 

luego se pone 

fmadm faulty

TIME            EVENT-ID                              MSG-ID         SEVERITY

---

Sep 05 16:28:08 29b28437-5ef3-48df-9945-d0cd69806b03  ZFS-8000-NX    Major

se pone fmadm repaired y el event -id

fmadm repaired 29b28437-5ef3-48df-9945-d0cd69806b03

se valida con el status
zpool status epool
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# renombrar repositorios

1ro ir a /etc/yum.repos.d

2do mv oracle.repo /etc/yum.repos.d/repos/

3ro vim oracle.repo ( se crea un repositorio con el vim y se anexa los repositorios al archivo)
------------------------------------------------------

[ol5_latest]

name=Oracle Linux $releasever Optional ($basearch) - Archive

baseurl=http://172.22.26.80/yum/OracleLinux/OL5/latest/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=1

#################################################################################

[ol6_latest]

name=Oracle Linux $releasever Latest ($basearch)

baseurl=http://172.22.26.80/yum/OracleLinux/OL6/latest/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=0

[ol6_addons]

name=Oracle Linux $releasever Add ons ($basearch)

baseurl=http://172.22.26.80/yum/OracleLinux/OL6/addons/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=0

#################################################################################

[ol7_latest]

name=Oracle Linux $releasever Latest ($basearch)

baseurl=http://172.22.26.80/yum/OracleLinux/OL7/latest/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=1

[ol7_UEKR5]

name=Latest Unbreakable Enterprise Kernel Release 5 for Oracle Linux $releasever ($basearch)

baseurl=http://172.22.26.80/yum/OracleLinux/OL7/UEKR5/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=0

[ol7_UEKR6]

name=Latest Unbreakable Enterprise Kernel Release 6 for Oracle Linux $releasever ($basearch)

baseurl=http://172.22.26.80/yum/OracleLinux/OL7/UEKR6/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=0

[ol7_addons]

name=Oracle Linux $releasever Add ons ($basearch)

baseurl=http://172.22.26.80/yum/OracleLinux/OL7/addons/$basearch/

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=1

[CentOS_Base]

name=CentOS $releasever Base ($basearch)

baseurl=http://172.22.26.80/yum/CentOS/7/base/CentOSbase

gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle

gpgcheck=0

enabled=1
------------------------------------------------------

4) yum clean all

5) yum reporlist all 

6) yum update

7) yum update --skin-broken
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
###################### Presentacion y despresentacion de discos ######################

1) identificar maquina o fisica 

2) Validar si el disco es fisico o virtual 

3) Disco fisico : ejecutar script hba muestra la información

nota :servicio multipath administra los discos fisicos

lsblk -o NAME,SERIAL,SIZE →> discos con lum

sudo blkid

con v se selecciona y con p se pega y para ejecutar un comando fuera de vi es con ! y comando

________________________________________________________________________

############################################ Despresentacion de disco fisico! ############################################
 
-Primero debemos saber cual fs vamos a desmontar el que viene con la lun es la misma label
umount /LIB34

-Sacamos una copia al /etc/multipath.conf
cp -p multipath.conf  multipath.conf_$(date +%d%b%Y-%H%M)

-Se debe borrar la LIB53 y la LUN en el multipath.conf
Y busca esa lun ahi en el /etc/multipath.conf

Se borra desde acá

___Acá____

multipath {
wwid                    360060e8012d1ad005040d1ad00000b7c (lun)
alias                   LIB53
}

_Hasta acá_

-Luego debemos refrescar (este paso demora dependiendo)
sudo multipath -rr

-Luego se ve valida si aparece aun:
multpath -ll | grep (el identificador de la lun)
###################### Ver ejemplo en 1.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/1.png) ######################
-Luego se da:
fdisk /dev/mapper/mpathakn

Luego se le oprime P, se sale con q

Luego se da :multipath -f mpathakn  (no deberia aparecer)
###################### Ver ejemplo en 2.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/2.png)  ######################

############################################ Presentación de disco ############################################
Se valida cual es el LIB O DATA QUE SIGUE ejemplo el ultimo era LIB53 el que sigue es el LIB54

Esperamos que no sden la LUN: 60060e8012d1ad005040d1ad00000b7d 4 TB (ejemplo)

-Se procede ir al script para escanear el cual es :
sh /usr/bin/tools/scanhba

luego deberia aparecer con el comando
multpath -ll | grep 360060e8012d1ad005040d1ad00000b7d
###################### Ver ejemplo en 3.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/3.png)  ######################
-Se procede a crear el fs LIB54

mkdir /LIB54

-Luego se modifica el /etc/multipath.conf original se debe sacar copia en ./backup

ejemplo multipath.conf_Feb162024_ec6439a

Para no cagarla copiar desde 

multipath {
wwid                    360060e8012d1ad005040d1ad00000b7d (lun)
alias                      LIB54
}

sudo multipath -l |grep dm- (asi tal cual para ver los alias)

sudo multipath -l |grep dm- |grep -i LIB |sort -h ( me ordena de mayor a menor)

y modificarlo en un bloc de notas por lo que la lun y el alias

-Luego dar multipath -rr para recargar

Luego darle formato xfs ( se valida antes con df -hT para ver que version tiene)

sudo blkid
mkfs.xfs /dev/mapper/LIB54

-Luego se monta con:
mount /dev/mapper/LIB54 /LIB54

-Luego se agrega al fstab:
###################### Ver ejemplo en 4.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/4.png) ######################
Guardar y listo!.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
############################################ Asignación de discos ############################################

- Se escanea discos con el siguiente comando: pdta: no saldra solo es para rescaneo (ejecutar en root)
for i in `ls /sys/class/scsi_host/`; do echo "- - -" >> /sys/class/scsi_host/$i/scan; done
- validar si funciona con multipath ejecutando:
multipath -ll 
si sale información buscarlo con multipath -ll |grep -i lun

      mpathn (360050768108081eda800000000000fff) dm-73 IBM ,2145

 mpathn es el nombre del disco
 ###################### Ver ejemplo en 5.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/5.png) ######################

 - Ahora se busca el disco con el lun :
lsscsi --scsi_id --size --wwn |grep -i lun

si aparece varios discos en lsscsi es que está por multipath y luego se ejecuta:
oracleasm querydisk

luego ejecutar:

oracleasm querydisk /dev/mapper/nombredisco  - esto es para validar si esta marcado como asm-

oracleasm createdisk nombre_grupo /dev/mapper/disco
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
############################################ Rear es copia de s.o ############################################

se configura en etc/rear

si no esta el paquete toca yum install rear

el archivo es local.conf dentro de /etc/rear

se debe excluir los file system que no sean de s.o en el local.conf
 ###################### Ver ejemplo en 6.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/6.png) ######################
 validar que se esta compartiendo desde el ruster
 ###################### Ver ejemplo en 7.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/7.png) ######################
 ###################### Ver ejemplo en 8.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/8.png) ######################
 ###################### Ver ejemplo en 9.png (https://github.com/Zilder92/Linux/blob/main/Imagenes/9.png) ######################
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------

############################################ CONFIGURACION RUTA PERMANENTE SERVER MEDIA AGENTE ############################################

Reinicio de confianza

cuando se crea a un host se pone base 32 osea /32
cuando se crea al segmento del red se pone base 24 osea /24

xsos -i

ip r |grep el nombre de la interfaz de servicios

ejemplo: sudo ip route add **172.18.88.92**/24 via 172.18.88.1 dev ens34 (ahi queda manera estatica si se reinicia pierde la ruta)

arp -a  es para ver la tabla de enrutamiento descubrimiento de host 

sudo ip route add (la ip a crear /base) via la ip gateway intfaz de servicio que voy a crear dev (divice o dispositivo ) y el bond y si aparece @bond es que depende del bond ejemplo: bond0.2802@bond0

100.64.1.0/25 via 172.22.88.1

ip r |grep bond0.2802 

default via 10.110.200.1 dev bond0.2802
10.110.200.0/24 dev bond0.2802 proto kernel scope link src 10.110.200.11
**100.64.1.0/25 via 10.110.200.1 dev bond0.2802**
169.254.0.0/16 dev bond0.2802 scope link metric 1010

se debe validar si ya ha sido creado 

ip r |grep 100.64

100.64.1.0/25 via 10.110.200.1 dev bond0.2802

cd /etc/sysconfig/network-scripts/

se debe poner ip a crear y la via que se creo por ejemplo **100.64.1.0/25 via 172.22.88.1**
------------------------------------------------------------------------------------------------------------------------------------------------------------------------